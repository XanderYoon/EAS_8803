{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Formatting\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Data Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Preprocessing\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Regressors\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Deep Learning\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Clustering\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df_train = pd.read_csv('train_data.csv')                #2000-2012\n",
    "df_validation = pd.read_csv('validation_data.csv')      #2013-2016\n",
    "df_test = pd.read_csv('test_data.csv')                  #2017-2020\n",
    "\n",
    "# Converting dates into months, dates are non-numeric\n",
    "df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "df_validation['date'] = pd.to_datetime(df_validation['date'])\n",
    "df_test['date'] = pd.to_datetime(df_test['date'])\n",
    "\n",
    "df_train['month'] = df_train['date'].dt.month\n",
    "df_validation['month'] = df_validation['date'].dt.month\n",
    "df_test['month'] = df_test['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "X_train = df_train.drop(columns=['score', 'D', 'date'])\n",
    "y_train = df_train[['score']]\n",
    "\n",
    "X_validation = df_validation.drop(columns=['score', 'D', 'date'])\n",
    "y_validation = df_validation[['score']]\n",
    "\n",
    "X_test = df_test.drop(columns=['score', 'D', 'date'])\n",
    "y_test = df_test[['score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = MinMaxScaler() \n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_validation_scaled = scaler.transform(X_validation)\n",
    "x_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine selected features with target variable 'D'\n",
    "X_train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_train_df['score'] = y_train\n",
    "\n",
    "# Calculate the correlation matrix between features and the target 'score'\n",
    "correlation_with_target = X_train_df.corr()['score'].drop('score') \n",
    "\n",
    "# Filter features with absolute correlation >= 0.1\n",
    "filtered_correlation = correlation_with_target[correlation_with_target.abs() >= 0.1]\n",
    "\n",
    "# Reshape the filtered correlations to a DataFrame\n",
    "filtered_correlation_df = filtered_correlation.to_frame().transpose()\n",
    "\n",
    "# Plotting the heatmap for the filtered correlations\n",
    "plt.figure(figsize=(12, 2)) \n",
    "sns.heatmap(filtered_correlation_df, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Heatmap of Features (|r| >= 0.1)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data points to display (first sixth of the data)\n",
    "subset_length = len(X_train_df) // 6\n",
    "\n",
    "# Plot scatter plots for each feature vs y ('score') for the first sixth of the data\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, feature in enumerate(filtered_correlation_df.columns):\n",
    "    plt.subplot(3, 4, i+1)\n",
    "    # Scatter plot using only the first sixth of the data\n",
    "    plt.scatter(X_train_df[feature].iloc[:subset_length], y_train.iloc[:subset_length], alpha=0.5)\n",
    "    plt.title(f'{feature} vs score')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = LassoCV(alphas=[1e-4], cv=5, random_state=42).fit(X_train_scaled, y_train)\n",
    "\n",
    "# If X_train_scaled is a NumPy array, use the original DataFrame X_train for feature names\n",
    "feature_names = X_train.columns  # Ensure this refers to the DataFrame version of the features\n",
    "\n",
    "# Extract Lasso coefficients\n",
    "lasso_coefficients = lasso_model.coef_\n",
    "\n",
    "# Create a DataFrame with feature names and their corresponding Lasso coefficients\n",
    "coeff_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': lasso_coefficients\n",
    "})\n",
    "\n",
    "# Sort by absolute value of the coefficients and return the top features\n",
    "top_features = coeff_df.reindex(coeff_df['Coefficient'].abs().sort_values(ascending=False).index).head(8)\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data points to display (first sixth of the data)\n",
    "subset_length = len(X_train_df) // 6\n",
    "\n",
    "# Plot scatter plots for each feature vs y ('score') for the first sixth of the data\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, feature in enumerate(top_features['Feature']):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    # Scatter plot using only the first sixth of the data\n",
    "    plt.scatter(X_train_df[feature].iloc[:subset_length], y_train.iloc[:subset_length], alpha=0.5)\n",
    "    plt.title(f'{feature} vs score')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine selected features with target variable 'score'\n",
    "X_train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_train_df['score'] = y_train\n",
    "\n",
    "# Select the features for transformation\n",
    "selected_features = ['PS', 'T2MDEW', 'TS', 'T2M_MAX', 'PRECTOT']\n",
    "\n",
    "# Define transformations\n",
    "def apply_transformations(df, features):\n",
    "    transformed_data = {}\n",
    "\n",
    "    for feature in features:\n",
    "        # Original feature (no transformation)\n",
    "        transformed_data[f'original_{feature}'] = df[feature]\n",
    "        \n",
    "        # Log transform (shift data to avoid log(0))\n",
    "        transformed_data[f'log_{feature}'] = np.log(df[feature] + 1)\n",
    "\n",
    "        # Exponential transform\n",
    "        transformed_data[f'exp_{feature}'] = np.exp(df[feature])\n",
    "\n",
    "        # Square root transform (shift data to avoid sqrt(negative))\n",
    "        transformed_data[f'sqrt_{feature}'] = np.sqrt(df[feature].clip(lower=0))\n",
    "\n",
    "        # Reciprocal transform (avoid divide by zero)\n",
    "        transformed_data[f'reciprocal_{feature}'] = 1 / (df[feature] + 1e-6)\n",
    "\n",
    "        # Box-Cox transform (shift data to positive and apply Box-Cox)\n",
    "        if (df[feature] > 0).all():  # Box-Cox requires positive data\n",
    "            transformed_data[f'boxcox_{feature}'], _ = boxcox(df[feature])\n",
    "        else:\n",
    "            shifted_feature = df[feature] - df[feature].min() + 1  # Shift to positive values\n",
    "            transformed_data[f'boxcox_{feature}'], _ = boxcox(shifted_feature)\n",
    "\n",
    "    return pd.DataFrame(transformed_data)\n",
    "\n",
    "# Apply transformations\n",
    "transformed_df = apply_transformations(X_train_df, selected_features)\n",
    "\n",
    "# Number of data points to display (first sixth of the data)\n",
    "subset_length = len(X_train_df) // 6\n",
    "transformed_df = transformed_df.iloc[:subset_length]\n",
    "score_subset = X_train_df['score'].iloc[:subset_length]\n",
    "\n",
    "# Plotting original and transformed features vs 'score'\n",
    "plt.figure(figsize=(20, 16))\n",
    "plot_num = 1\n",
    "\n",
    "for feature in selected_features:\n",
    "    # Plot for original feature and each transformation\n",
    "    for transform in ['original', 'log', 'exp', 'sqrt', 'reciprocal', 'boxcox']:\n",
    "        transformed_feature = f'{transform}_{feature}'\n",
    "        plt.subplot(len(selected_features), 6, plot_num)\n",
    "        plt.scatter(transformed_df[transformed_feature], score_subset, alpha=0.5)\n",
    "        plt.title(f'{transform}({feature}) vs score')\n",
    "        plt.xlabel(transformed_feature)\n",
    "        plt.ylabel('score')\n",
    "        plot_num += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine selected features with target variable 'score'\n",
    "X_train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_train_df['score'] = y_train\n",
    "\n",
    "# Select the features for transformation\n",
    "selected_features = ['PS', 'T2MDEW', 'TS', 'T2M_MAX', 'PRECTOT']\n",
    "\n",
    "# Apply log transform to the selected features (shift to avoid log(0))\n",
    "X_log_transformed = np.log(X_train_df[selected_features] + 1)\n",
    "\n",
    "# Standardize the log-transformed data before applying PCA\n",
    "scaler = StandardScaler()\n",
    "X_log_scaled = scaler.fit_transform(X_log_transformed)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_log_scaled)\n",
    "\n",
    "# Number of data points to display (first sixth of the data)\n",
    "subset_length = len(X_train_df) // 6\n",
    "X_pca_subset = X_pca[:subset_length]\n",
    "score_subset = X_train_df['score'].iloc[:subset_length]\n",
    "\n",
    "# Plotting PC1 vs PC2, colored by score\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(X_pca_subset[:, 0], X_pca_subset[:, 1], c=score_subset, cmap='viridis', alpha=0.7)\n",
    "plt.title('PC1 vs PC2 (Log-Transformed Features)')\n",
    "plt.xlabel('Principal Component 1 (PC1)')\n",
    "plt.ylabel('Principal Component 2 (PC2)')\n",
    "plt.colorbar(scatter, label='score')  # Add a colorbar to show score values\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PC1 vs score\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_pca_subset[:, 0], score_subset, alpha=0.7)\n",
    "plt.title('PC1 vs score')\n",
    "plt.xlabel('Principal Component 1 (PC1)')\n",
    "plt.ylabel('score')\n",
    "\n",
    "# Plot PC2 vs score\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_pca_subset[:, 1], score_subset, alpha=0.7)\n",
    "plt.title('PC2 vs score')\n",
    "plt.xlabel('Principal Component 2 (PC2)')\n",
    "plt.ylabel('score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca, X_test_pca, y_train_subset, y_test_subset = train_test_split(X_pca, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', random_state=42),\n",
    "}\n",
    "\n",
    "# Train, predict, and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train_pca, y_train_subset)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    \n",
    "    # Print model performance\n",
    "    print(f'--- {model_name} ---')\n",
    "    print(f'Accuracy: {accuracy_score(y_test_subset, y_pred):.4f}')\n",
    "    print(f'Classification Report:\\n{classification_report(y_test_subset, y_pred)}')\n",
    "    print(f'Confusion Matrix:\\n{confusion_matrix(y_test_subset, y_pred)}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual for one of the classifiers (e.g., Logistic Regression)\n",
    "model = models['Decision Tree']\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_subset, y_pred, alpha=0.7, color='b')\n",
    "plt.title('Predicted vs Actual (Decision Tree)')\n",
    "plt.xlabel('Actual target')\n",
    "plt.ylabel('Predicted target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual for one of the classifiers (e.g., Logistic Regression)\n",
    "model = models['Random Forest']\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_subset, y_pred, alpha=0.7, color='b')\n",
    "plt.title('Predicted vs Actual (Random Forest)')\n",
    "plt.xlabel('Actual target')\n",
    "plt.ylabel('Predicted target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted vs actual for one of the classifiers (e.g., Logistic Regression)\n",
    "model = models['SVM']\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_subset, y_pred, alpha=0.7, color='b')\n",
    "plt.title('Predicted vs Actual (SVM)')\n",
    "plt.xlabel('Actual target')\n",
    "plt.ylabel('Predicted target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'K-Means': KMeans(n_clusters=5, random_state=42),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'DBSCAN': DBSCAN(eps=0.5, min_samples=5),\n",
    "    'Gaussian Mixture Model (GMM)': GaussianMixture(n_components=5, random_state=42)\n",
    "}\n",
    "\n",
    "# Fit and predict clusters for models that don't require fitting the training target\n",
    "for model_name, model in models.items():\n",
    "    if model_name == 'K-Nearest Neighbors':\n",
    "        # For KNN, we need target labels, so let's assume we're using cluster centers from K-Means\n",
    "        kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "        labels = kmeans.fit_predict(X_pca)\n",
    "        model.fit(X_pca, labels)\n",
    "        y_pred = model.predict(X_pca)\n",
    "    else:\n",
    "        y_pred = model.fit_predict(X_pca)\n",
    "    \n",
    "    # Calculate silhouette score for clustering quality\n",
    "    if model_name != 'K-Nearest Neighbors':  # Silhouette doesn't apply to KNN as it requires labeled data\n",
    "        silhouette_avg = silhouette_score(X_pca, y_pred)\n",
    "        print(f'{model_name} Silhouette Score: {silhouette_avg:.4f}')\n",
    "    \n",
    "    # Plotting the clusters\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred, cmap='viridis', alpha=0.7)\n",
    "    plt.title(f'{model_name} Clustering (PC1 vs PC2)')\n",
    "    plt.xlabel('Principal Component 1')\n",
    "    plt.ylabel('Principal Component 2')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
